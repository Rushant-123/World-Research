---
title: "AI Researchers"
company: "Anthropic / OpenAI / DeepMind / Meta AI"
country: "USA / UK / Global"
selling_price: 100
inputs:
  - name: "PhD Education"
    cost: 30
    link: "phd-computer-science"
  - name: "Research Experience"
    cost: 20
    link: "research-publications"
  - name: "Workstations"
    cost: 10
    link: "engineering-workstation"
  - name: "GPU Compute Access"
    cost: 25
    link: "training-cluster"
  - name: "Salaries"
    cost: 15
    link: "compensation"
value_created: 0
---

# How to Make AI Researchers

AI researchers are the scientists and engineers who design, train, and improve large language models like Claude. They combine deep theoretical knowledge (mathematics, statistics, computer science) with practical engineering skills (distributed systems, GPU programming, software engineering).

## What is it?

A highly specialized workforce at the intersection of research and engineering. Unlike traditional academia (slow publication cycles, theoretical focus) or traditional software engineering (ship features, optimize metrics), AI research requires:

- **Deep mathematical understanding** (optimization, probability, information theory)
- **Ability to run experiments at scale** (thousands of GPUs, weeks of training)
- **Fast iteration** (frontier AI moves faster than any other field)
- **Safety consciousness** (models can cause harm if misaligned)

The talent pool is small — perhaps 2,000-5,000 people globally who can meaningfully contribute to frontier model development.

## Team Composition for Frontier Lab

| Role | Headcount | Salary Range (2024) |
|------|-----------|---------------------|
| Research Scientist | 50-150 | $300K-800K |
| Research Engineer | 100-300 | $250K-600K |
| Infrastructure Engineer | 50-100 | $200K-400K |
| Safety/Alignment Researcher | 20-50 | $250K-500K |
| Product Engineer | 50-150 | $200K-400K |
| Leadership/Management | 20-50 | $400K-1M+ |

Total: 300-800 people at a frontier lab like Anthropic or OpenAI

## Steps to Make an AI Researcher:

**Phase 1: Undergraduate Foundation (4 years)**

1. Complete [Bachelor's degree](bachelor-degree) in Computer Science, Mathematics, Physics, or Electrical Engineering
2. Core coursework: linear algebra, calculus, probability/statistics, algorithms, data structures
3. Take electives in machine learning, deep learning, optimization theory
4. Learn Python deeply — it's the language of ML
5. Build projects: implement papers, train small models, participate in Kaggle competitions
6. Maintain high GPA (3.7+) for top PhD programs
7. Develop research taste: read papers, understand what makes research important vs. incremental
8. Find undergraduate research opportunities with ML faculty

**Phase 2: PhD Training (4-6 years)**

9. Apply to top [PhD programs](phd-computer-science) in ML/AI: Stanford, MIT, Berkeley, CMU, Princeton, Toronto, Mila
10. Admission requires: strong GPA, research experience, GRE scores, letters from known researchers
11. Join a lab with advisor working on relevant problems (language models, RL, safety, scaling)
12. Year 1-2: coursework, reading groups, small projects, find thesis direction
13. Identify research area: language models, multimodal, RLHF, interpretability, safety, scaling laws
14. Year 3-4: main thesis research, publish at top venues (NeurIPS, ICML, ICLR, ACL, EMNLP)
15. Need 3-5 first-author publications at top venues for competitive positions
16. Internships at frontier labs (Anthropic, OpenAI, DeepMind, Google Brain, Meta AI)
17. Internship is critical: most hires come from intern pipeline
18. Year 5-6: finish thesis, job search, defense

**Phase 3: Key Skills Developed**

19. **Mathematical foundations:**
    - Optimization: gradient descent, Adam, second-order methods
    - Probability: Bayesian inference, information theory, entropy
    - Linear algebra: matrix decomposition, eigenvalues, attention mechanisms
    - Statistics: hypothesis testing, confidence intervals, A/B testing

20. **Deep learning fundamentals:**
    - Architectures: transformers, attention, FFN, normalization
    - Training: loss functions, regularization, learning rate schedules
    - Scaling: parallelism strategies, communication patterns
    - Debugging: gradient issues, loss spikes, training instabilities

21. **Large-scale systems:**
    - Distributed training: data parallel, tensor parallel, pipeline parallel
    - GPU programming: CUDA basics, memory hierarchy, kernel optimization
    - Infrastructure: Slurm, Kubernetes, checkpointing, fault tolerance
    - Data pipelines: tokenization, batching, shuffling at scale

22. **Research methodology:**
    - Experimental design: ablations, baselines, statistical significance
    - Paper writing: clear communication, reproducibility, honest reporting
    - Peer review: evaluating others' work, responding to criticism
    - Collaboration: working in teams, code reviews, knowledge sharing

**Phase 4: Industry Hiring**

23. Apply to frontier labs 6-12 months before graduation
24. Interview process (typical):
    - Resume screen (publications, advisor reputation, internships)
    - Phone screen (1-2 hours): ML fundamentals, coding
    - On-site (4-8 hours): research talk, technical deep dives, coding
    - Team matching: find right project fit

25. Evaluation criteria:
    - Research impact (citations, but also taste)
    - Technical depth (can you really build things?)
    - Ability to scale (can you work with 10,000 GPUs, not just 8?)
    - Alignment with lab mission (especially important for safety-focused labs like Anthropic)
    - Collaboration skills (research is increasingly team-based)

26. Compensation (2024, top US labs):
    - Research Scientist (new PhD): $300K-500K total comp
    - Senior Research Scientist (3-5 years): $500K-800K total comp
    - Staff/Principal: $700K-1.2M total comp
    - Distinguished/VP: $1M-3M+ total comp

**Phase 5: On-the-Job Development**

27. Join team working on specific area (pre-training, RLHF, safety, evals, product)
28. Ramp-up period: 3-6 months to become productive
29. Access to [GPU compute](training-cluster) that no university can match
30. Learn internal tools, codebases, processes
31. Participate in training runs (watching a model train for months builds intuition)
32. Publish when possible (labs vary in publication policy)
33. Develop intuitions: what experiments to try, what to ignore
34. Career progression: larger projects, more autonomy, eventually leading research directions

## Specialized Roles

**Alignment/Safety Researcher:**
- Focus on making models helpful, harmless, and honest
- Constitutional AI, RLHF, red-teaming, interpretability
- Often philosophy/ethics background in addition to ML
- Critical for Anthropic specifically

**Scaling Researcher:**
- Understand scaling laws, efficient architectures
- Make training cheaper/faster without sacrificing quality
- Heavy systems/infrastructure overlap

**Interpretability Researcher:**
- Understand what's happening inside models
- Mechanistic interpretability, probing, concept detection
- More neuroscience/cognitive science flavor

**Evaluation Researcher:**
- Design benchmarks, measure capabilities
- Detect dangerous capabilities before deployment
- Heavy overlap with product/safety

## Why the Talent Pool is Small

1. **PhD bottleneck:** Only ~500 ML PhDs graduate per year from top programs
2. **Advisor quality:** Best training comes from working with top 50-100 advisors globally
3. **Compute access:** Hard to do frontier research without frontier compute
4. **Absorbing capacity:** Only 5-10 labs doing frontier work, each hiring 50-100/year
5. **Attrition:** Some go to startups, hedge funds, or different research areas
6. **Geographic concentration:** Most roles require Bay Area, NYC, or London presence

This scarcity drives the extremely high compensation — frontier AI researchers are among the highest-paid technical workers in the world.
