---
title: "Verification Software and Simulation Tools"
company: "Synopsys / Cadence / Siemens"
country: "USA"
selling_price: 15
inputs:
  - name: "Software Development"
    cost: 8
    link: "software-engineering"
  - name: "Compiler Technology"
    cost: 2
    link: "compiler-development"
  - name: "Hardware Acceleration"
    cost: 3
    link: "fpga-emulation"
  - name: "Algorithm Research"
    cost: 1.5
    link: "verification-algorithms"
  - name: "Testing Infrastructure"
    cost: 0.5
    link: "qa-infrastructure"
value_created: 0
---

# How to Make Verification Software and Simulation Tools

Software for verifying integrated circuit designs function correctly before fabrication. Verification: 60-70% of chip design effort. Bug found in silicon: $1-10M to fix (mask respins, schedule delays, reputation damage). Bug found in verification: $1K-10K (engineer time to fix). Tools: simulators, emulators, formal verification, coverage analysis, assertion checking.

**Step 1-15: Event-Driven Simulation Engine**
Core simulator architecture: event-driven simulation (discrete event simulation, DES). Time advances by discrete steps (events). Event: signal transition (0→1, 1→0, X→1, etc.) at specific time. Event queue: priority queue sorted by time, holds future events. Main loop: (1) Remove earliest event from queue. (2) Advance simulation time to event time. (3) Evaluate gate/module driven by changed signal. (4) Calculate new output value and transition time. (5) Schedule new event if output changed. (6) Repeat until queue empty or max time reached. Four-value logic: 0 (low), 1 (high), X (unknown), Z (high-impedance). Nine-value extensions include strength (supply, strong, weak). Implemented in C++ for performance. Kernel: 500K-1M lines of code. [Software engineers](software-engineering) optimize critical paths (event queue operations, gate evaluation). Use profiling tools (VTune, perf), optimize hot functions.

**Step 16-30: HDL [Compiler](compiler-development) and Elaboration**
Parse Verilog/SystemVerilog or VHDL source code. Lexical analysis (tokenization), syntax analysis (parse tree), semantic analysis (type checking, scope resolution). Generate internal representation (IR): netlist graph (modules, instances, ports, nets, primitives). Elaboration: resolve hierarchies, generate statements, parameters, loop unrolling. Example: for-loop generating 1,000 flip-flop instances becomes 1,000 nodes in elaborated design. Constant propagation, dead code elimination. Sensitivity list analysis: which signals trigger which always blocks. Compile to optimized simulation data structures: arrays of gate structs, event structs. Incremental compilation: recompile only changed modules (saves time during debug cycles). Compiler: 300K-500K lines of code (reuses open-source: ANTLR for parsing, LLVM for optimization passes).

**Step 31-45: Compiled-Code Simulation**
Faster alternative to event-driven: compile HDL to C/C++, then to native machine code, execute. 10-100× faster than interpreted simulation. Cycle-based (evaluate all logic every clock cycle, not event-driven). No intra-cycle timing (assumes zero delay within cycle, valid for synchronous designs). Flow: (1) Analyze HDL, partition into sequential (flip-flops) and combinational (gates between FFs). (2) Generate C++ code: function per module, evaluate combinational cloud, update flip-flops on clock edge. (3) Compile C++ with g++ or clang (optimization flags: -O3, -march=native). (4) Execute binary. Hybrid simulators: use compiled-code for fast blocks, event-driven for accurate timing in critical blocks. Development: 200K-400K lines. Challenge: compile time (large designs: 30-60 minutes to compile HDL → C++). Trade-off: compile once, simulate many times (regression tests).

**Step 46-62: [Hardware Acceleration](fpga-emulation) and Emulation**
Large designs (10-50 billion transistors): software simulation too slow (1-10 kHz clock, days to boot OS). Hardware acceleration: compile design into FPGAs, run at MHz clock rates. Emulation systems: Synopsys ZeBu, Cadence Palladium, Siemens Veloce. Architecture: 1,000-10,000 large FPGAs (Xilinx Virtex, Intel Stratix) connected with high-speed interconnect. Compilation flow: (1) Synthesize RTL to FPGA netlists. (2) Partition design across FPGAs (minimize inter-FPGA signals - communication bottleneck). (3) Place-and-route on each FPGA. (4) Program FPGAs, interconnect, run. Speed: 1-10 MHz emulated clock (1,000-10,000× faster than software). Can boot Linux, run real workloads. Use cases: software bring-up (OS, drivers), performance validation, system-level test. Emulator cost: $5-30M per system (capital equipment). Compile time: 12-48 hours (large SoC). Rent time: $10K-50K/week (hosted emulation services). Development of emulator hardware and software: 150-250 engineer-years.

**Step 63-78: Formal Verification Tools**
Mathematical proof of correctness (no test vectors, exhaustive). Techniques: (1) Equivalence checking: prove RTL matches gate-level netlist (post-synthesis). Represent both as canonical forms (BDDs: binary decision diagrams, or AIGs: and-inverter graphs), compare. Mismatch indicates synthesis bug or unintended optimization. (2) Model checking: verify properties (assertions) hold in all reachable states. Temporal logic: LTL (linear temporal logic), CTL (computational tree logic). Example property: "req signal always followed by ack within 5 cycles." Explore state space (symbolic: BDDs, SAT-based). State explosion problem: N flip-flops → 2^N states (intractable for large N). Abstraction techniques: cone of influence reduction, case splitting, induction. (3) SAT/SMT solving: boolean satisfiability (SAT) - find variable assignment satisfying formula, or prove UNSAT. SMT (satisfiability modulo theories) - extends SAT with arithmetic, arrays. Algorithms: DPLL, CDCL (conflict-driven clause learning), watch literals. Tools: Z3, MiniSat, CVC4. [Formal verification algorithms](verification-algorithms): research-heavy, published at CAV, FMCAD conferences. Development: 100-150 engineer-years for formal tool suite.

**Step 79-93: Assertion-Based Verification**
Embed properties in RTL code (SystemVerilog Assertions - SVA, or Property Specification Language - PSL). Assertions checked during simulation or formal verification. Types: (1) Immediate assertions: combinational checks (assert expression evaluates true). Example: `assert (addr < MEM_SIZE);`. (2) Concurrent assertions: temporal checks. Example: `assert property (@(posedge clk) req |-> ##[1:5] ack);` (req implies ack within 1-5 cycles). (3) Cover properties: specify interesting scenarios (coverage targets). Simulator instruments assertions: check at runtime, report violations (time, location, values). Bind assertions to modules (separate file, non-intrusive). Formal tools: prove assertions hold or find counterexample. Accelerates debug: assertion fires → pinpoint bug location. Assertion library: standard protocols (AXI, PCIe, DDR) have pre-written assertion IP.

**Step 94-108: Coverage Analysis**
Measure verification completeness. Types: (1) Code coverage: which lines of RTL executed. Line coverage, branch coverage (both sides of if/else), toggle coverage (every signal toggled 0→1 and 1→0), FSM coverage (all states visited, all transitions taken). (2) Functional coverage: user-defined scenarios. SystemVerilog covergroups: `covergroup cg @(posedge clk); addr_cp: coverpoint addr { bins low = {[0:63]}; bins high = {[64:127]}; } endgroup`. Cross coverage: combinations (addr × opcode). Track coverage percentage (goal: >95% functional coverage before tapeout). Coverage-driven verification: generate random stimulus, check coverage, add directed tests for uncovered scenarios. Coverage database: store results from thousands of regression tests, merge, generate report. Development: 80-120K lines of code for coverage infrastructure.

**Step 95-110: Testbench and UVM Methodology**
Universal Verification Methodology (UVM): SystemVerilog class library for building reusable, structured testbenches. Components: (1) Driver: converts transactions to pin wiggles. (2) Monitor: observes pin activity, extracts transactions. (3) Scoreboard: checks DUT outputs against expected (reference model). (4) Sequencer: generates transaction sequences (constrained-random). (5) Agent: groups driver, monitor, sequencer. (6) Environment: top-level testbench container. Phases: build, connect, run, check, report. Configuration database: pass parameters down hierarchy. Factory pattern: override component types. Objection mechanism: control test end. Constrained random: `class Transaction; rand bit [31:0] addr; constraint valid_addr { addr < 1024; } endclass`. Solver finds values satisfying constraints. Seeds: different seeds → different random sequences (regression suite: 1,000-10,000 seeds). Reference model: golden functional model (C++, SystemC, or Python) computes expected outputs. Compare DUT vs reference. Testbench code: often 3-5× larger than RTL code (10K lines RTL → 30K-50K lines testbench).

**Step 111-122: Regression and [QA Infrastructure](qa-infrastructure)**
Nightly regressions: run thousands of tests automatically. Compute cluster: 100-1,000 CPUs, LSF or SGE job scheduler. Each test: randomized seed, different configuration. Collect results: pass/fail status, coverage data, waveforms (for failures), logs. Regression dashboard: web interface showing test status, coverage trends over time, failure rates. Fail triage: on-call engineer investigates new failures (DUT bug vs testbench bug vs infrastructure issue). Bisect: identify commit causing failure (git bisect automation). Bug tracking: file issues in Jira, assign to RTL owner. Simulation licenses: FlexLM floating licenses (100-500 concurrent licenses, ~$200K/year each). Compute costs: $1-5M/year (servers, storage, power). Total regression runtime: 50,000-200,000 CPU-hours per night (for large SoC project).

**Step 123-135: Performance Optimization**
Simulation is compute-bound. Optimizations: (1) Parallel simulation: partition design into independent blocks, simulate on multiple cores (synchronization at clock boundaries). Speedup: 2-8× on multicore. (2) Incremental compilation: cache compiled objects, recompile only changed files. (3) Fast RAM: 2-4 GB/s memory bandwidth bottleneck - optimize data structures (cache-friendly, minimize pointer chasing). (4) Snapshot/restore: checkpoint simulation state (save memory image), restart from checkpoint (skip boot sequences). (5) Smart compilation: analyze design, identify synthesizable vs behavioral code (optimize differently). (6) Distributed simulation: multi-machine (10-100 servers), MPI or custom RPC. Amdahl's law limits: synchronization overhead. (7) GPU acceleration: experimental (dataflow graphs on CUDA), limited adoption (FPGA emulation more effective). Benchmark: 1M gates simulate at 1-10 kHz in software, 1-10 MHz in compiled-code, 1-10 GHz (real-time) in emulation.

**Step 136-145: Licensing and Market**
Simulator market: Synopsys VCS (~45% share), Cadence Xcelium (~35%), Siemens Questa (~20%). Pricing: $200K-400K/year per license (floating, concurrent users). Large design teams: 50-200 simulation licenses. Emulators: $5-30M capital cost, often amortized over 3-5 years. Formal tools: $150K-300K/year. Total verification tool budget for large chip project: $10-50M over project lifetime (4-5 years). ROI: prevent multi-million dollar silicon respins. Industry consolidation: Synopsys acquired Synplicity, SpringSoft (Verdi). Cadence acquired Verisity (Specman), Forte Design (high-level synthesis). Open-source alternatives: Verilator (very fast compiled-code simulator, widely used for small/medium designs, free), Icarus Verilog (interpreted, slow, free), GHDL (VHDL simulator). Commercial quality gap: advanced features (UVM, SVA, debug, performance) not available in open-source.

Development timeline: 10-15 years to build competitive verification toolset. Ongoing: 300-800 engineers (large EDA company's verification division). Interoperability: VCS and Xcelium use same testbench code (UVM standard, IEEE 1800.2). Debug tools: waveform viewers (Verdi, DVE, SimVision) - indispensable, 100K-200K lines of GUI code. Price in context: $15 represents allocated cost of verification software per chip designed. Actual cost: $10-50M tools ÷ 300K chips = $30-170 per chip. The $15 value is simplified allocation representing portion of chip design verification effort (not total project verification cost).
